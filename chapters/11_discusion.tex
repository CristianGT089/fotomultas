\section{Discusión y análisis}

La pregunta de investigación interrogó cómo mitigar el riesgo de pérdida o alteración de la integridad de los datos asociados al proceso de fotocomparendos mediante tecnologías de redes distribuidas que garantizaran registro, trazabilidad, autenticidad y confidencialidad. Los resultados obtenidos en el entorno experimental sugieren que la implementación de una arquitectura híbrida, integrando Hyperledger Fabric para la gestión de datos sensibles, Ethereum para la publicación de metadatos verificables e IPFS para el almacenamiento distribuido de evidencia, permite responder afirmativamente a dicha interrogante, aunque de manera \textbf{parcial y condicionada al alcance del prototipo}. Específicamente, los hallazgos validan el análisis de vulnerabilidades estructurales del sistema FÉNIX mediante auditoría documental, el desarrollo de un prototipo funcional con arquitectura hexagonal y mecanismos de inmutabilidad criptográfica, y la evaluación técnica mediante plan de pruebas V\&V que arrojó tiempos de respuesta menores a 3 segundos y rechazo del 100\% de intentos de modificación no autorizada. No obstante, es imperativo establecer desde el inicio la distinción fundamental entre \textbf{verificación} (\textit{verification}) y \textbf{validación} (\textit{validation}) en el ciclo de vida del software: mientras el prototipo demuestra que el sistema fue construido correctamente según especificaciones técnicas (verificación de requisitos funcionales en laboratorio), no constituye una validación operativa que demuestre que el sistema funcionará adecuadamente bajo la carga real de 457.000 comparendos semestrales ni con la variabilidad de datos heterogéneos del RUNT y SIMIT \parencite{boehm1984,iso25010}. Este alcance metodológico condiciona toda la interpretación subsiguiente de los hallazgos.

\paragraph{Cierre explícito de la pregunta de investigación.}
En síntesis de respuesta a la pregunta de investigación, los resultados evidencian que la mitigación del riesgo de alteración de integridad se logró técnica y criptográficamente para las dimensiones de \textit{registro} y \textit{trazabilidad}: el registro inmutable de transiciones de estado (PENDING, PAID, APPEALED, RESOLVED\_APPEAL, CANCELLED) mediante eventos de smart contract con timestamps criptográficos demostró, en el entorno de prueba, una resistencia del 100\% a intentos de modificación \textit{ex post}, respondiendo al componente de integridad de la pregunta. La \textit{autenticidad} se satisfizo mediante la verificación de hashes IPFS (CID) contra registros blockchain, estableciendo una cadena de custodia digital detectable algorítmicamente. La \textit{confidencialidad} se resolvió arquitectónicamente segregando datos sensibles en Hyperledger Fabric (Private Data Collections) de metadatos públicos en Ethereum, cumpliendo con la Ley 1581 de 2012. Sin embargo, esta respuesta es \textbf{condicionada y parcial}: solo abarcó cinco de los ocho estados conceptuales del proceso (excluyendo NOTIFICADA y CERRADA), operó exclusivamente con datos sintéticos que no reflejan la variabilidad de placas extranjeras, vehículos especiales o inconsistencias del RUNT real, y no pudo validar la integridad \textit{ex ante} (veracidad de la captura fotográfica frente a fallas de calibración de cámaras). Por tanto, la tecnología blockchain demostró viabilidad para garantizar la integridad de datos \textit{una vez ingresados} al sistema, pero no para asegurar la veracidad de la evidencia física ni para operar a escala institucional sin degradación de rendimiento, aspectos que requieren validación empírica adicional antes de considerar la respuesta como definitiva.

\subsection{Análisis técnico-arquitectónico: decisiones de diseño, trade-offs y riesgos de implementación}

El análisis de las vulnerabilidades del sistema FÉNIX, en términos puramente arquitectónicos, revela que sus debilidades son estructurales: la dependencia de bases de datos relacionales centralizadas configura un único punto de fallo (\textit{single point of failure}) donde la integridad lógica depende de controles de acceso administrativos rather than de propiedades criptográficas del protocolo. Desde la perspectiva de ingeniería de sistemas, esto representa una deuda técnica de diseño donde la mutabilidad inherente a SQL (operaciones UPDATE/DELETE) es incompatible con los requisitos de auditoría forense para evidencia sancionatoria.

La consecución del desarrollo del prototipo se materializó en una arquitectura hexagonal que separa responsabilidades mediante servicios especializados: \textit{HyperledgerService} para operaciones privadas, \textit{EthereumService} para publicación de hashes, y \textit{SyncService} para orquestación. Los resultados funcionales demuestran que el prototipo implementó cinco estados críticos del ciclo de vida del comparendo (PENDING, PAID, APPEALED, RESOLVED\_APPEAL, CANCELLED) con trazabilidad completa mediante eventos de smart contract, validando así el requisito de trazabilidad del objetivo general. La evidencia de integridad —100\% de coincidencia entre hashes de IPFS y registros blockchain— valida el requisito de autenticidad.

\paragraph{Decisiones de trade-off explícitas.}
Se evaluó inicialmente una arquitectura puramente pública en Ethereum \parencite{yousfi2022}, pero se descartó al proyectar costos de gas variables para un volumen de 457.000 comparendos anuales, lo cual violaría los principios de sostenibilidad presupuestal de entidades públicas colombianas y expondría datos personales sensibles en violación de la Ley 1581 de 2012. Se evaluó igualmente una solución exclusiva en Hyperledger Fabric, pero se determinó que carecería de la verificabilidad pública sin autenticación que exige el principio de transparencia de la Ley 1712 de 2014. La decisión final sacrificó la simplicidad operativa de una única tecnología (aumento de la complejidad cognitiva del equipo de mantenimiento) para ganar el equilibrio jurídico-técnico: Fabric gestiona el 90\% de las operaciones internas con >1.000 TPS y sin costos de gas, mientras Ethereum asume solo la publicación de hashes (15-30 TPS aceptable para metadatos públicos), optimizando costos y latencia sin sacrificar la verificabilidad ciudadana.

\paragraph{Riesgos técnicos residuales.}
El \textit{SyncService} —componente Node.js responsable de la sincronización entre Fabric y Ethereum— operó en el prototipo como un proceso monolítico, constituyendo un \textit{Single Point of Failure} no mitigado que representa un riesgo de diseño crítico para la consistencia eventual entre cadenas. Si este servicio falla durante la sincronización, se genera un estado "huérfano" donde la multa existe en la red privada pero no es verificable públicamente, introduciendo una ventana de inconsistencia temporal de aproximadamente 5 segundos que, aunque tolerable para registro de infracciones, sería inaceptable para sistemas de pago en tiempo real. Adicionalmente, la dependencia de la disponibilidad continua de nodos IPFS para el \textit{pinning} de evidencias constituye un riesgo de persistencia: sin el mantenimiento activo de al menos un nodo con el contenido "anclado", los datos podrían volverse inaccesibles aunque su hash permanezca inmutable en blockchain.

En términos de métricas de diseño de software, la arquitectura alcanza un acoplamiento aferente (Ca) bajo en el módulo de blockchain, permitiendo sustituir Ethereum por Polygon sin modificar la lógica de negocio (principio OCP). Sin embargo, la complejidad operativa de mantener una red Hyperledger Fabric con múltiples organizaciones requiere competencias especializadas en gestión de certificados PKI y políticas de \textit{endorsement} que trascienden las capacidades típicas de equipos de TI gubernamentales estándar, representando una barrera de entrada significativa para la replicabilidad operativa.

\subsection{Implicaciones socio-técnicas e institucionales: proyecciones de impacto y marco normativo}

Paralelamente al análisis técnico, es necesario examinar cómo la arquitectura propuesta altera los flujos organizacionales y la relación entre ciudadanía e institución. El sistema FÉNIX actual genera una asimetría informacional donde la legitimidad de los registros se presume pero no puede ser verificada autónomamente por el afectado, situación que la jurisprudencia constitucional colombiana ha señalado como riesgo para el debido proceso \parencite{corte2018}. La tasa de impugnación del 34,1 \% y las más de 155.000 PQRSD semestrales deben interpretarse no solo como indicadores de ineficiencia, sino como síntomas de una crisis de confianza institucional donde la opacidad técnica facilita la discrecionalidad administrativa.

Los resultados vinculados a la evaluación técnica permiten proyectar —bajo condiciones ideales simuladas— un escenario de impacto socio-técnico potencial. El tiempo promedio de verificación de integridad se situó en aproximadamente 2,7 segundos en el entorno de prueba, contrastando con los tiempos actuales del modelo manual, donde la resolución de una PQRSD puede extenderse por días o semanas. Desde una argumentación cuantitativa proyectada (no empírica), la posibilidad de verificación autónoma en segundos, frente a la espera de días en el sistema actual, sugiere una \textbf{hipótesis fundada} de reducción potencial de la carga operativa asociada a las PQRSD. No obstante, es imperativo matizar que estas cifras constituyen \textbf{proyecciones teóricas simuladas}, no impactos reales demostrados, dado que el estudio no realizó modelado econométrico detallado ni midió directamente la reducción de litigios en condiciones reales de operación.

La arquitectura resuelve la tensión entre inmutabilidad y derecho al olvido (art. 15, Ley 1581/2012) mediante \textbf{borrado criptográfico}: la revocación de claves de acceso a colecciones privadas en Fabric, combinada con el cese de \textit{pinning} en IPFS, hace los datos criptográficamente inaccesibles sin violar la cadena de bloques, satisfaciendo el requisito legal de supresión sin comprometer la integridad del ledger \parencite{voigt2017}. Este mecanismo es crucial desde la perspectiva institucional, ya que permite cumplir con mandatos normativos aparentemente contradictorios (transparencia vs. privacidad) sin incurrir en nulidades administrativas por violación de datos personales.

Desde el punto de vista de la gobernanza algorítmica, el consorcio propuesto (SDM, Policía, Contraloría) representa una transición desde la confianza en una única entidad hacia un protocolo de consenso multiinstitucional. Como señala Swan \parencite{swan2015}, esto no implica eliminación de la autoridad, sino su redistribución mediante protocolos criptográficos. Sin embargo, es relevante señalar que este modelo introduce el riesgo del "error inmutable": en el sistema FÉNIX, los errores de digitación se corrigen mediante UPDATE en base de datos; en el sistema propuesto, la rectificación requiere transacciones adicionales (ej. \textit{CANCELLED}) que dejan evidencia permanente del fallo inicial. Este efecto de visibilidad obligatoria fortalece la rendición de cuentas, pero introduce tensiones institucionales entre eficiencia operativa (ocultar errores para mantener reputación) y transparencia radical (visibilizar fallos como parte del historial público).

\subsection{Posicionamiento crítico frente al estado del arte}

El posicionamiento del prototipo frente a las propuestas existentes revela diferencias arquitectónicas sustanciales. Respecto a los enfoques basados exclusivamente en blockchains públicas \parencite{yousfi2022}, el presente trabajo es \textbf{superior en privacidad y sostenibilidad económica proyectada}, al evitar la exposición pública de datos personales y los costos variables de gas, pero es \textbf{equivalente en transparencia} para metadatos públicos y \textbf{conscientemente inferior en descentralización radical}, aceptando la distribución institucional como trade-off necesario para el cumplimiento normativo colombiano. Frente a los modelos híbridos que mantienen bases de datos tradicionales como capa primaria \parencite{chen2024}, este prototipo es \textbf{superior en garantías de inmutabilidad técnica}, al eliminar completamente la mutabilidad de la capa de datos crítica, pero asume una \textbf{mayor complejidad operativa} documentada. Comparado con soluciones exclusivas en Hyperledger Fabric (registros vehiculares gubernamentales en Estonia), el aporte es \textbf{superior en verificabilidad pública}, al incorporar la capa Ethereum que permite consulta sin autenticación.

\subsection{Limitaciones del estudio: alcance metodológico, institucional y ecológico}

Más allá de las restricciones técnicas de escalabilidad ya discutidas, es imperativo explicitar las limitaciones metodológicas y de diseño experimental que condicionan la generalización de los hallazgos. En primer lugar, el estudio adoptó un \textbf{diseño de investigación experimental puro} (laboratorio controlado) rather than un diseño cuasi-experimental o de campo, lo cual introduce sesgos de validez ecológica significativos. La imposibilidad de acceder a datos reales de comparendos —derivada de restricciones legales de protección de datos personales (Ley 1581/2012) y políticas de reserva de información de la SDM— obligó al uso de datos sintéticos generados mediante scripts de prueba. Esta limitación metodológica implica que el prototipo no fue expuesto a la variabilidad, inconsistencias y casos atípicos que caracterizan los datos del mundo real (ej. placas extranjeras, vehículos diplomáticos, formatos heterogéneos de registro en el RUNT), lo cual podría influir en la lógica de negocio y en el manejo de errores en un entorno de producción.

En segundo lugar, la \textbf{validez interna} de las pruebas de rendimiento está limitada por el sesgo de selección inherente al entorno controlado: las 80 pruebas automatizadas se ejecutaron en hardware optimizado, red local sin latencia de internet, y sin carga concurrente de usuarios que simule la operación real de 457.000 comparendos semestrales. La ausencia de pruebas de estrés (\textit{stress testing}) con volúmenes masivos y la imposibilidad de evaluar el comportamiento del sistema bajo ataques de denegación de servicio (DoS) constituyen restricciones metodológicas que impiden afirmar la robustez operativa del sistema bajo condiciones adversas reales.

En tercer lugar, existen \textbf{limitaciones institucionales y de gobernanza} no resueltas en el alcance del prototipo. La integración con sistemas externos (RUNT y SIMIT) fue simulada mediante \textit{mocks} (servicios de prueba) rather than APIs reales, dado que el acceso a dichas interfaces requiere convenios interadministrativos formales y credenciales de producción que exceden el alcance de un proyecto de grado académico. Esta limitación institucional implica que no se validaron las latencias reales de servicios externos, los protocolos de comunicación específicos, ni los posibles cuellos de botella en la interoperabilidad con sistemas legados gubernamentales. Asimismo, la ausencia de validación con \textit{stakeholders} reales (agentes de tránsito, funcionarios de la Contraloría, ciudadanos usuarios finales) mediante estudios de aceptación tecnológica (TAM/UTAUT) constituye una restricción metodológica relevante: el éxito de adopción depende no solo de la viabilidad técnica, sino de la percepción de utilidad y facilidad de uso por parte de los actores institucionales, aspecto no evaluado empíricamente en este estudio.

Finalmente, la \textbf{validez externa} (generalización) está restringida por el contexto específico de Bogotá y su marco normativo colombiano. Aunque la arquitectura es conceptualmente replicable, las particularidades del Código Nacional de Tránsito, la jurisprudencia de la Corte Constitucional \parencite{corte2018} y la Ley 1581/2012 configuran un entorno legal que no necesariamente es trasladable a otras jurisdicciones sin adaptaciones sustanciales. La imposibilidad de realizar un piloto de campo con 5.000-10.000 multas reales —limitación derivada de barreras burocráticas y de acceso a datos— impide validar empíricamente las proyecciones de reducción de carga operativa y ROI estimado, manteniendo dichas inferencias en el ámbito de la estimación teórica rather than de la evidencia empírica directa.

\subsection{Direcciones de evolución técnica y validación operativa}

La transición desde la verificación técnica hacia la validación operativa requiere el desarrollo de tres líneas de evolución diferenciadas. \textbf{Desde la ingeniería de sistemas}, es prioritario: (a) la eliminación del SPOF del \textit{SyncService} mediante su re-arquitectura como un servicio distribuido con tolerancia a fallos (patrón \textit{circuit breaker} y colas de eventos redundantes); (b) la evaluación de estrategias de sharding en Fabric para manejar volúmenes reales de 457.000 comparendos semestrales sin degradación de latencia; y (c) la implementación de mecanismos de oráculo certificador para registrar estados físicos (notificación efectiva) y cerrar la brecha entre el mundo digital y el físico.

\textbf{Desde la perspectiva institucional y organizacional}, es imperativo: (a) la realización de estudios de aceptación tecnológica mediante modelos como TAM o UTAUT, evaluando la percepción de confianza y usabilidad por parte de agentes de tránsito y ciudadanos, aspecto crítico dado que el éxito de adopción depende más de la experiencia de usuario que de la robustez técnica subyacente; (b) la negociación de convenios interadministrativos formales para la gobernanza del consorcio blockchain; y (c) la realización de un piloto controlado con 5.000–10.000 multas reales que permita validar empíricamente las proyecciones de reducción de carga operativa, aspecto que el presente estudio no pudo realizar por restricciones de acceso a datos.

\subsection{Síntesis conclusiva y delimitación del alcance}

En síntesis, el prototipo constituye una respuesta técnica verificada frente a las deficiencias de integridad del sistema de fotocomparendos, respondiendo parcialmente a la pregunta de investigación mediante la demostración de viabilidad técnica de mecanismos criptográficos de inmutabilidad. Desde la perspectiva de ingeniería de sistemas, la arquitectura híbrida demuestra que es posible diseñar sistemas distribuidos que equilibran privacidad y transparencia mediante trade-offs explícitos entre rendimiento y descentralización, validando los objetivos específicos planteados en el alcance experimental. Desde la perspectiva institucional, los resultados sugieren un \textbf{potencial} de transformación de los flujos de confianza entre ciudadanía y Estado, proyectando una reducción hipotética de la fricción operativa asociada a litigios, aunque esta proyección requiere validación empírica en condiciones reales de operación.

La evidencia obtenida en el entorno de laboratorio —con datos sintéticos, volúmenes reducidos y ausencia de integración con sistemas reales— no permite afirmar la viabilidad operativa a escala completa ni la aceptación institucional del modelo de gobernanza distribuida propuesto. La blockchain debe entenderse como un componente técnico de un ecosistema de confianza más amplio, no como solución aislada, reconociendo que la verificación técnica exitosa es condición necesaria pero no suficiente para la validación operativa en el contexto de la administración pública distrital. La respuesta a la pregunta de investigación es, por tanto, \textbf{afirmativa pero condicionada}: las tecnologías de redes distribuidas permiten mitigar el riesgo de alteración de integridad \textit{dentro del sistema digital}, pero su efectividad completa depende de la resolución de limitaciones metodológicas, institucionales y de escalabilidad que trascienden el alcance del presente estudio experimental.